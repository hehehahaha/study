　　1.牛顿法：是通过求解目标函数的一阶导数为0时的参数，进而求出目标函数最小值时的参数。

　　　　　　　收敛速度很快。

　　　　　　　海森矩阵的逆在迭代过程中不断减小，可以起到逐步减小步长的效果。

　　　　　　　缺点：海森矩阵的逆计算复杂，代价比较大，因此有了拟牛顿法。

　　2.梯度下降法：是通过梯度方向和步长，直接求解目标函数的最小值时的参数。

　　　　　　　　　越接近最优值时，步长应该不断减小，否则会在最优值附近来回震荡。


https://www.cnblogs.com/lyr2015/p/9010532.html
